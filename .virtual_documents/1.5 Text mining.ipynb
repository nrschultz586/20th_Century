from textblob import TextBlob
import pandas as pd
import warnings
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
import nltk
import nltk
import re
nltk.download('stopwords')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger_eng')
nltk.download('averaged_perceptron_tagger')
from collections import Counter
sns.set()
# Suppress FutureWarning messages
warnings.simplefilter(action='ignore', category=FutureWarning)





myfile = open('KeyEvents20thCentury_article_Wiki.txt', encoding='utf-8')


# Import txt file

with open('KeyEvents20thCentury_article_Wiki.txt', 'r', errors='ignore') as file: 
   data = file.read().replace( '\n', ' ')





# Sentence tokenization

from nltk.tokenize import sent_tokenize
tokenized_sent = sent_tokenize(data)
print(tokenized_sent) 


# Word tokenization

from nltk.tokenize import word_tokenize
tokenized_word = word_tokenize(data)
print(tokenized_word) 


word_counts = Counter(tokenized_word)
most_common_words = word_counts.most_common(10)


common_words_df = pd.DataFrame(most_common_words, columns=["Word", "Count"])


plt.figure(figsize=(10, 6))
palette = sns.dark_palette("xkcd:blue", n_colors=len(common_words_df), reverse=False)
sns.barplot(data=common_words_df, x="Count", y="Word", palette=palette)
plt.title("Top 10 Most Common Words")
plt.xlabel("Frequency")
plt.ylabel("Words")
plt.show()





# Create frequency distribution

from nltk.probability import FreqDist
dist_words = FreqDist(tokenized_word)
print(dist_words)


dist_words.most_common(10)


from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
stop_words = set(stopwords.words("english"))


# Removing stopwords in words

filtered_words = [] # creates an empty list
for word in tokenized_word:
      if word not in stop_words:
           filtered_words.append(word)


# Create a new FreqDist for filteredâ€“words

dist_words_filter = FreqDist(filtered_words)
print (dist_words_filter)


# Substitute all punctuation marks with a space

sans_punc = re.sub("[^a-zA-Z]",  # Search for all non-letters
                        " ",        # Replace all non-letters with spaces
                        str(filtered_words))


# Word tokenization

tokenized_word_2 = word_tokenize(sans_punc)
#print (tokenized_word_2)


# Create a new FreqDist

dist_words_filter_2 = FreqDist(tokenized_word_2) 


# Count the most common filtered words
word_counts_filtered = dist_words_filter_2.most_common(10)


# Create a DataFrame for visualization
filtered_words_df = pd.DataFrame(word_counts_filtered, columns=["Word", "Count"])
filtered_words_df


plt.figure(figsize=(10, 6))
palette = sns.dark_palette("xkcd:blue", n_colors=len(common_words_df), reverse=False)
sns.barplot(data=filtered_words_df, x="Count", y="Word", palette=palette)
plt.title("Top 10 Most Common Words (Excluding Stopwords and Punctuation)")
plt.xlabel("Frequency")
plt.ylabel("Words")
plt.show()








new_stopwords = ["And", "Then", 'n', 't', 's', 'The']

filtered = []
for word in tokenized_word_2:
     if word not in new_stopwords:
        filtered.append(word)


%%time
text = TextBlob(str(filtered))


tags_list = text.tags


tags_list





df_text = pd.DataFrame(tags_list)
df_text.columns = [ 'Words', "Word type"]


df_text.head()


df_t = df_text.groupby('Word type').count().reset_index()


df_t.head()


top10 = df_t.nlargest(10, 'Words')


top10





plt.figure(figsize = (10, 5))
palette = sns.dark_palette("xkcd:blue", n_colors=len(common_words_df), reverse=False)
with sns.dark_palette("xkcd:blue", 20):
      sns.barplot(x = "Words", y = "Word type", palette = palette,
     saturation = 0.9, data = top10).set_title("Key Events 20th Century Wiki Article - top 10 word types used")








df = df_text[(df_text['Word type'] == "NN") | (df_text['Word type'] == "NNS") | (df_text['Word type'] == "NNP")]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurences'], ascending=False)
top15_noun = y.nlargest(15, 'Occurences')


top15_noun


plt.figure(figsize=(10, 5))
palette = sns.dark_palette("xkcd:blue", n_colors=len(top15_noun), reverse=False)
with sns.dark_palette("xkcd:blue", 15):
    sns.barplot(x="Word", y="Occurences", palette=palette,
    saturation=0.9, data = top15_noun).set_title("Key Events 20th Century Wiki Article - Top 15 most frequently used nouns")






df = df_text[(df_text['Word type'] == "VB")  | (df_text['Word type'] == "VBD")]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurences'], ascending=False)
top15_verb = y.nlargest(15, 'Occurences')


top15_verb


plt.figure(figsize = (10, 5))
palette = sns.dark_palette("xkcd:blue", n_colors=len(top15_verb), reverse=False)
with sns.dark_palette("xkcd:blue", 10):
    sns.barplot(x = "Word", y = "Occurences", palette=palette,
    saturation = 0.9, data = top15_verb).set_title(" Key Events 20th Century Wiki Article - Top 15 most frequently used verbs")
    plt.xticks(rotation=45)





df = df_text[df_text['Word type'] == "JJ"]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by=['Occurences'], ascending=False)
top15_adjective = y.nlargest(15, 'Occurences')


top15_adjective


plt.figure(figsize=(10, 5))
palette = sns.dark_palette("xkcd:blue", n_colors=len(top15_adjective), reverse=False)
with sns.dark_palette("xkcd:blue", 10):
    sns.barplot(x="Word", y="Occurences", palette=palette,
    saturation=0.9, data=top15_adjective).set_title("Key Events 20th Century Wiki Article - Top 15 most frequently used adjectives")
    plt.xticks(rotation=45)








listToStr = ' '.join([str(elem) for elem in filtered])
print(listToStr)


# Create a count for the countries

all_counts = Counter(re.sub(r'\W+', ' ', listToStr).split())


countries = pd.read_csv("countries_list.csv")
countries.head()


cntry_list = countries['Country'].to_list()


dict_of_counts = {d : all_counts[d] for d in cntry_list}


#Search for the names from the list in the dictionary

dct = {v:[k] for v,k in dict_of_counts.items()}
df = pd.DataFrame(dct)


df


df = df.transpose().reset_index()
df.dtypes


df


df.rename(columns = {"index":"Country", 0:"Times mentioned"}, inplace = True)


df


mentions_df = df.sort_values(by='Times mentioned', ascending=False).reset_index(drop=True)


mentions_df.head()





# Drop rows where 'Mentions' is 0
mentions_df2 = mentions_df.loc[mentions_df['Times mentioned'] > 0].reset_index(drop=True)
mentions_df2


plt.figure(figsize=(10, 15))
palette = sns.dark_palette("#79C", n_colors=len(mentions_df2), reverse=False)
with sns.dark_palette("#79C", 27):
    sns.barplot(x = "Times mentioned", y = "Country", palette=palette,
    saturation=0.9, data = mentions_df2.sort_values("Times mentioned", ascending = False)).set_title("Key Events 20th Century Wiki Article - most frequently mentioned countries")






