# Import libraries

import pandas as pd
import time
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import matplotlib.pyplot as plt 
import os
import logging


service = Service(r'C:\Program Files (x86)\Chrome Driver\chromedriver-win64\chromedriver.exe')
driver = webdriver.Chrome(service=service)


# Get the pageâ€™s contents

page_url = "https://simple.m.wikipedia.org/wiki/List_of_countries"
driver.get(page_url)


from bs4 import BeautifulSoup
import requests 


# Get URL

page_url =  requests.get("https://simple.m.wikipedia.org/wiki/List_of_countries")


# Create soup 

soup = BeautifulSoup(page_url.text, 'html.parser')


# Find and filter the list of countries
countries = []
for link in soup.find_all("a"):
    href = link.get("href")
    if "/wiki/" in str(href) and ":" not in str(href):
        countries.append(link.text.strip())


# Remove duplicates and sort the list
countries = sorted(list(set(countries)))

# Save the list of countries to a text file
with open("countries_list.txt", "w", encoding="utf-8") as file:
