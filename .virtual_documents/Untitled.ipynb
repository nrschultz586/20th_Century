# import libraries
import pandas as pd
import numpy as np
import spacy
from spacy import displacy
import networkx as nx
import os
import matplotlib.pyplot as plt
import scipy
import re


# Download English module

!python -m spacy download en_core_web_sm


# Load spacy English module

NER = spacy.load("en_core_web_sm")





# Load the text file

with open('KeyEvents20thCentury_article_Wiki.txt', 'r', errors='ignore') as file: 
   data = file.read().replace( '\n', ' ')


data





# Clean the text file to remove unnecessary elements
# Remove lines with navigation, menus, or tooltips
cleaned_text = re.sub(r'(\n\s*\n)+', '\n', data)  # Remove excessive newlines
cleaned_text = re.sub(r'\[edit\]', '', cleaned_text)   # Remove '[edit]' markers
cleaned_text = re.sub(r'[^A-Za-z0-9 .,\'\-\n]', '', cleaned_text)  # Remove special characters


cleaned_text_path = 'C:/Users/nrsmi/Documents/CareerFoundry/20th_Century/20thCentury_cleaned.txt'
with open(cleaned_text_path, 'w', encoding='utf-8') as cleaned_file:
    cleaned_file.write(cleaned_text)


# Load the text file

with open('20thCentury_cleaned.txt', 'r', errors='ignore') as file: 
   data_cleaned = file.read().replace( '\n', ' ')


data_cleaned





# Find all mentions of the United States and its variations in the cleaned text
us_variations = re.findall(r'\b(?:United States|America|USA|U\.S\.|US)\b', cleaned_text, re.IGNORECASE)


# Create a list of unique variations of the name
unique_us_variations = set(us_variations)
unique_us_variations


countries_list = pd.read_csv("countries_list.csv")
countries_list.head()


# Add individual alias columns directly
countries_list['Alias_1'] = None
countries_df['Alias_2'] = None
countries_df['Alias_3'] = None
countries_df['Alias_4'] = None





#txt = NER(data)



