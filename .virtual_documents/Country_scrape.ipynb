# Import libraries

import pandas as pd
import time
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import matplotlib.pyplot as plt 
import os
import logging


service = Service(r'C:\Program Files (x86)\Chrome Driver\chromedriver-win64\chromedriver.exe')
driver = webdriver.Chrome(service=service)


# Get the pageâ€™s contents

page_url = "https://simple.m.wikipedia.org/wiki/List_of_countries"
driver.get(page_url)


from bs4 import BeautifulSoup
import requests 


# Get URL

page_url =  requests.get("https://simple.m.wikipedia.org/wiki/List_of_countries")


# Create soup 

soup = BeautifulSoup(page_url.text, 'html.parser')


# Find and filter the list of countries
countries = []
for link in soup.find_all("a"):
    href = link.get("href")
    if "/wiki/" in str(href) and ":" not in str(href):
        countries.append(link.text.strip())


# Remove duplicates and sort the list
countries = sorted(list(set(countries)))


countries


# Put the countries into a dataframe

df = pd.DataFrame(countries, columns = ["Country"])
df


df = df.drop(0)
df


file_path = 'C:/Users/nrsmi/Documents/CareerFoundry/20th_Century/countries_list.csv' 
df.to_csv(file_path, index=False)



